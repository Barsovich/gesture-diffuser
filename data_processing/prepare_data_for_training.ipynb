{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "from pymo.preprocessing import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pymo.parsers import BVHParser\n",
    "from pymo.viz_tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--transcript_dir', dest='transcript_dir',\n",
    "#                     type=str, help='Directory for transcripts')\n",
    "# parser.add_argument('--motion_dir', dest='transcript_dir',\n",
    "#                     type=str, help='Directory for transcripts')\n",
    "# parser.add_argument('--transcript_out_dir', dest='transcript_out_dir',\n",
    "#                     type=str, help='Directory for transcripts')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# motion_dir = args.motion_dir\n",
    "# transcript_dir = args.transcript_dir\n",
    "# transcript_out_dir = args.transcript_out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_dir = \"../data/V1/allRec/\"\n",
    "transcript_dir = \"../data/V1/allRecTranscripts/\"\n",
    "transcript_out_dir = \"../data/V1/transcriptsProcessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_files = [f for f in listdir(\n",
    "    motion_dir) if isfile(join(motion_dir, f))]\n",
    "recording_files.sort()\n",
    "motion_files = [join(motion_dir, recording_files[i]) for i in range(len(recording_files))]\n",
    "transcript_files = [join(transcript_dir, recording_files[i].replace(\n",
    "    'bvh', 'json')) for i in range(len(recording_files))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_size = 5 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507.3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_to_float(str_time: str) -> float:\n",
    "  return float(str_time[:-1])\n",
    "string_to_float(\"507.300s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sectionize(transcript_files, clip_size, start_offset=0):\n",
    "  all_transcripts = []\n",
    "  for file_id in range(len(transcript_files)):\n",
    "    with open(transcript_files[file_id]) as f:\n",
    "      transcript = json.load(f)\n",
    "\n",
    "    # Collect all sections into a list\n",
    "    words = []\n",
    "    for section_id in range(len(transcript)):\n",
    "      section = transcript[section_id]\n",
    "      if len(section[\"alternatives\"]) != 1:\n",
    "        print(\"\\n\\n\\nBe careful, there are more than an alternative!\\n\\n\\n\")\n",
    "      words_in_section = section[\"alternatives\"][0][\"words\"]\n",
    "      words += words_in_section\n",
    "    \n",
    "    # Sectionize the words\n",
    "    if not exists(transcript_out_dir):\n",
    "      mkdir(transcript_out_dir)\n",
    "    \n",
    "    words_sectioned = []\n",
    "    current_clip_start = start_offset\n",
    "    words_counter = 0\n",
    "\n",
    "    # Set the sections empty until there the first word occurance\n",
    "    first_detected_word_start = string_to_float(words[words_counter][\"start_time\"])\n",
    "    while first_detected_word_start > current_clip_start:\n",
    "      words_sectioned += [{\"start\": current_clip_start,\n",
    "                          \"end\": current_clip_start + clip_size, \"words\": []}]\n",
    "      current_clip_start += clip_size\n",
    "\n",
    "    while words_counter < len(words):\n",
    "      # If a words start is before section start but end is after the section start, we want to include that word in the section\n",
    "      while words_counter > 1 and \\\n",
    "        current_clip_start < string_to_float(words[words_counter - 1][\"end_time\"]) < current_clip_start + clip_size:\n",
    "        words_counter -= 1\n",
    "\n",
    "      # Add all words in the section to a list\n",
    "      words_in_section = []\n",
    "\n",
    "      while words_counter < len(words) and string_to_float(words[words_counter][\"start_time\"]) < current_clip_start + clip_size:\n",
    "        words_in_section.append(words[words_counter][\"word\"])\n",
    "        words_counter += 1\n",
    "      words_sectioned += [{\"start\": current_clip_start,\n",
    "                          \"end\": current_clip_start + clip_size, \"words\": words_in_section}]\n",
    "      current_clip_start += clip_size\n",
    "    all_transcripts.append(words_sectioned)\n",
    "  return all_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts_0 = sectionize(transcript_files, clip_size, start_offset=0)\n",
    "all_transcripts_2_5 = sectionize(transcript_files, clip_size, start_offset=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 38)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num_words_per_section = max([max([len(all_transcripts_0[j][i]['words']) for i in range(\n",
    "    len(all_transcripts_0[j]))]) for j in range(len(all_transcripts_0))])\n",
    "max_num_words_per_section\n",
    "max_num_words_per_section2_5 = max([max([len(all_transcripts_2_5[j][i]['words']) for i in range(\n",
    "    len(all_transcripts_2_5[j]))]) for j in range(len(all_transcripts_2_5))])\n",
    "max_num_words_per_section, max_num_words_per_section2_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2641, 2629)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sections_total_0 = sum([len(all_transcripts_0[j])\n",
    "                         for j in range(len(all_transcripts_0))])\n",
    "\n",
    "num_sections_total_2_5 = sum([len(all_transcripts_2_5[j])\n",
    "                         for j in range(len(all_transcripts_2_5))])\n",
    "num_sections_total_0, num_sections_total_2_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(transcript_out_dir, f\"processed_words_into_sections_{clip_size}s_offset{0}s.json\"), \"w\") as f:\n",
    "  json.dump(all_transcripts_0, f)\n",
    "with open(join(transcript_out_dir, f\"processed_words_into_sections_{clip_size}s_offset{2_5}s.json\"), \"w\") as f:\n",
    "  json.dump(all_transcripts_2_5, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = Pipeline([\n",
    "    ('param', MocapParameterizer('position')),\n",
    "    ('rcpn', RootCentricPositionNormalizer()),\n",
    "    ('delta', RootTransformer('abdolute_translation_deltas')),\n",
    "    ('const', ConstantsRemover()),\n",
    "    ('np', Numpyfier()),\n",
    "    ('down', DownSampler(2)),\n",
    "    ('stdscale', ListStandardScaler())\n",
    "])\n",
    "parsed_data_list = []\n",
    "for motion_file in motion_files:\n",
    "  parser = BVHParser()\n",
    "  parsed_data = parser.parse(motion_file)\n",
    "  parsed_data_list.append(parsed_data)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piped_data = data_pipe.fit_transform([parsed_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./processed_motion\", piped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Aug  3 2021, 19:21:54) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fb60b568b9eafea3dac73304166ce4cbcca6e97c109218915796e4b74930d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
