{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/barissen/projects/gesture-diffuser/data/allAudio/1-1.wav\"\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Word:\n",
    "    ''' A class representing a word from the JSON format for vosk speech recognition API '''\n",
    "\n",
    "    def __init__(self, dict):\n",
    "        '''\n",
    "        Parameters:\n",
    "          dict (dict) dictionary from JSON, containing:\n",
    "            conf (float): degree of confidence, from 0 to 1\n",
    "            end (float): end time of the pronouncing the word, in seconds\n",
    "            start (float): start time of the pronouncing the word, in seconds\n",
    "            word (str): recognized word\n",
    "        '''\n",
    "\n",
    "        self.conf = dict[\"conf\"]\n",
    "        self.end = dict[\"end\"]\n",
    "        self.start = dict[\"start\"]\n",
    "        self.word = dict[\"word\"]\n",
    "\n",
    "    def to_string(self):\n",
    "        ''' Returns a string describing this instance '''\n",
    "        return \"{:20} from {:.2f} sec to {:.2f} sec, confidence is {:.2f}%\".format(\n",
    "            self.word, self.start, self.end, self.conf*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:11:12:13:14:15\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from vosk-model-en-us-0.22/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from vosk-model-en-us-0.22/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from vosk-model-en-us-0.22/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo vosk-model-en-us-0.22/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from vosk-model-en-us-0.22/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from vosk-model-en-us-0.22/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from vosk-model-en-us-0.22/rnnlm/final.raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the                  from 0.09 sec to 20.16 sec, confidence is 100.00%\n",
      "the                  from 20.19 sec to 40.32 sec, confidence is 100.00%\n",
      "three                from 40.32 sec to 60.48 sec, confidence is 39.29%\n",
      "three                from 60.48 sec to 80.64 sec, confidence is 31.82%\n",
      "the                  from 80.67 sec to 100.80 sec, confidence is 100.00%\n",
      "the                  from 100.83 sec to 120.96 sec, confidence is 100.00%\n",
      "the                  from 120.99 sec to 141.12 sec, confidence is 100.00%\n",
      "the                  from 141.15 sec to 161.28 sec, confidence is 100.00%\n",
      "the                  from 161.31 sec to 181.44 sec, confidence is 100.00%\n",
      "the                  from 181.47 sec to 201.60 sec, confidence is 100.00%\n",
      "the                  from 201.63 sec to 221.76 sec, confidence is 100.00%\n",
      "the                  from 221.79 sec to 241.92 sec, confidence is 100.00%\n",
      "the                  from 241.95 sec to 262.08 sec, confidence is 100.00%\n",
      "the                  from 262.11 sec to 282.24 sec, confidence is 100.00%\n",
      "the                  from 282.27 sec to 302.40 sec, confidence is 100.00%\n",
      "the                  from 302.43 sec to 322.56 sec, confidence is 100.00%\n",
      "the                  from 322.59 sec to 342.72 sec, confidence is 100.00%\n",
      "the                  from 342.75 sec to 362.88 sec, confidence is 100.00%\n",
      "the                  from 362.91 sec to 383.04 sec, confidence is 100.00%\n",
      "the                  from 383.07 sec to 403.20 sec, confidence is 100.00%\n",
      "the                  from 403.23 sec to 423.36 sec, confidence is 100.00%\n",
      "the                  from 423.39 sec to 443.52 sec, confidence is 100.00%\n",
      "the                  from 443.55 sec to 463.68 sec, confidence is 100.00%\n",
      "the                  from 463.71 sec to 483.84 sec, confidence is 100.00%\n",
      "the                  from 483.87 sec to 504.00 sec, confidence is 100.00%\n",
      "the                  from 504.03 sec to 524.16 sec, confidence is 100.00%\n",
      "the                  from 524.19 sec to 544.32 sec, confidence is 100.00%\n",
      "the                  from 544.35 sec to 564.48 sec, confidence is 100.00%\n",
      "the                  from 564.51 sec to 584.64 sec, confidence is 100.00%\n",
      "the                  from 584.67 sec to 604.80 sec, confidence is 100.00%\n",
      "three                from 605.31 sec to 625.47 sec, confidence is 38.96%\n",
      "three                from 625.47 sec to 645.63 sec, confidence is 38.45%\n",
      "the                  from 645.66 sec to 665.79 sec, confidence is 100.00%\n",
      "the                  from 665.82 sec to 685.95 sec, confidence is 100.00%\n",
      "the                  from 685.98 sec to 706.11 sec, confidence is 100.00%\n",
      "the                  from 706.14 sec to 726.27 sec, confidence is 100.00%\n",
      "the                  from 726.30 sec to 746.43 sec, confidence is 100.00%\n",
      "the                  from 746.46 sec to 766.59 sec, confidence is 100.00%\n",
      "the                  from 766.62 sec to 786.75 sec, confidence is 100.00%\n",
      "the                  from 786.78 sec to 806.91 sec, confidence is 100.00%\n",
      "the                  from 806.94 sec to 827.07 sec, confidence is 100.00%\n",
      "the                  from 827.10 sec to 847.23 sec, confidence is 100.00%\n",
      "the                  from 847.26 sec to 867.39 sec, confidence is 100.00%\n",
      "the                  from 867.51 sec to 879.63 sec, confidence is 100.00%\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import json\n",
    "\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "\n",
    "model_path = \"vosk-model-en-us-0.22\"\n",
    "audio_filename = \"/Users/barissen/projects/gesture-diffuser/data/allAudio/1-1.wav\"\n",
    "\n",
    "model = Model(model_path)\n",
    "wf = wave.open(audio_filename, \"rb\")\n",
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "rec.SetWords(True)\n",
    "\n",
    "# get the list of JSON dictionaries\n",
    "results = []\n",
    "# recognize speech using vosk model\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        part_result = json.loads(rec.Result())\n",
    "        results.append(part_result)\n",
    "part_result = json.loads(rec.FinalResult())\n",
    "results.append(part_result)\n",
    "\n",
    "# convert list of JSON dictionaries to list of 'Word' objects\n",
    "list_of_words = []\n",
    "for sentence in results:\n",
    "    if len(sentence) == 1:\n",
    "        # sometimes there are bugs in recognition\n",
    "        # and it returns an empty dictionary\n",
    "        # {'text': ''}\n",
    "        continue\n",
    "    for obj in sentence['result']:\n",
    "        w = Word(obj)  # create custom Word object\n",
    "        list_of_words.append(w)  # and add it to list\n",
    "\n",
    "wf.close()  # close audiofile\n",
    "\n",
    "# output to the screen\n",
    "for word in list_of_words:\n",
    "    print(word.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Aug  3 2021, 19:21:54) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fb60b568b9eafea3dac73304166ce4cbcca6e97c109218915796e4b74930d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
